{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer, Lambda, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to image directory\n",
    "car = glob.glob('/Users/austinau-yeung/Documents/Georgia Tech/1/ECE6254/project/cardiomegaly2/*')\n",
    "ede = glob.glob('/Users/austinau-yeung/Documents/Georgia Tech/1/ECE6254/project/edema2/*')\n",
    "\n",
    "# parameters\n",
    "car_train_num = 400\n",
    "ede_train_num = 400\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# select random subset of images for training\n",
    "car_train = np.random.choice(car,size=car_train_num,replace=False)\n",
    "ede_train = np.random.choice(ede,size=ede_train_num,replace=False)\n",
    "car = list(set(car)-set(car_train))\n",
    "ede = list(set(ede)-set(ede_train))\n",
    "car_test = car\n",
    "ede_test = ede\n",
    "\n",
    "car_test_num = len(car_test)\n",
    "ede_test_num = len(ede_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "IMG_DIM = (IMG_WIDTH,IMG_HEIGHT)\n",
    "\n",
    "# load training images\n",
    "car_train_imgs = [img_to_array(load_img(img,target_size=IMG_DIM,color_mode=\"grayscale\")) for img in car_train]\n",
    "ede_train_imgs = [img_to_array(load_img(img,target_size=IMG_DIM,color_mode=\"grayscale\")) for img in ede_train]\n",
    "\n",
    "# create corresponding labels\n",
    "train_imgs = np.array(car_train_imgs+ede_train_imgs)\n",
    "train_imgs_scaled = train_imgs.astype('float32')/255\n",
    "train_labels = car_train_num*['c']+ede_train_num*['e']\n",
    "\n",
    "# load test images and create corresponding labels\n",
    "car_test_imgs = [img_to_array(load_img(img,target_size=IMG_DIM,color_mode=\"grayscale\")) for img in car_test]\n",
    "ede_test_imgs = [img_to_array(load_img(img,target_size=IMG_DIM,color_mode=\"grayscale\")) for img in ede_test]\n",
    "test_imgs = np.array(car_test_imgs+ede_test_imgs)\n",
    "test_imgs_scaled = test_imgs.astype('float32')/255\n",
    "test_labels = car_test_num*['c']+ede_test_num*['e']\n",
    "\n",
    "input_shape = (IMG_HEIGHT,IMG_WIDTH,train_imgs.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class labels as 0/1\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_enc = le.transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese network referenced from the following:\n",
    "# https://github.com/keras-team/keras/blob/master/examples/mnist_siamese.py\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 40\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def resnet_base(input_shape):\n",
    "    resnet = ResNet50(include_top=False,weights=None,input_shape=input_shape,pooling=None)\n",
    "    output = resnet.layers[-1].output\n",
    "    output = keras.layers.Flatten()(output)\n",
    "    resnet = Model(resnet.input,output)\n",
    "    for layer in resnet.layers:\n",
    "        layer.trainable=True\n",
    "\n",
    "    x = resnet.output\n",
    "    \n",
    "#     imgIn = Input(shape=input_shape)\n",
    "#     x = Flatten()(imgIn)\n",
    "#     x = Dense(128, activation='relu')(x)\n",
    "#     x = Dropout(0.1)(x)\n",
    "#     x = Dense(128, activation='relu')(x)\n",
    "#     x = Dropout(0.1)(x)\n",
    "#     x = Dense(128, activation='relu')(x)\n",
    "        \n",
    "    return Model(resnet.input,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create positive and negative pairs\n",
    "idx = [np.where(train_labels_enc==i)[0] for i in range(num_classes)]\n",
    "tr_pairs, tr_y = create_pairs(train_imgs_scaled,idx)\n",
    "\n",
    "idx = [np.where(test_labels_enc==i)[0] for i in range(num_classes)]\n",
    "te_pairs, te_y = create_pairs(test_imgs_scaled,idx)\n",
    "\n",
    "# create siamese network with euclidean distance as final layer\n",
    "base_network = resnet_base(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance,output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# setup image augmentation on pairs of images using ImageDataGenerator, referenced from the following:\n",
    "# https://github.com/keras-team/keras/issues/3386#issuecomment-237555199\n",
    "\n",
    "def trainGenerator( X, I, Y):\n",
    "\n",
    "    while True:\n",
    "        # shuffled indices    \n",
    "        idx = np.random.permutation( X.shape[0])\n",
    "        # create image generator\n",
    "        datagen = ImageDataGenerator(\n",
    "                fill_mode='constant',\n",
    "                cval=0,\n",
    "                rescale=1./1,\n",
    "                featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                rotation_range=5, #180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                width_shift_range=0.05, #0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.05, #0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=False)  # randomly flip images\n",
    "\n",
    "        batches = datagen.flow( X[idx], Y[idx], batch_size=64, shuffle=False)\n",
    "        idx0 = 0\n",
    "        for batch in batches:\n",
    "            idx1 = idx0 + batch[0].shape[0]\n",
    "\n",
    "            yield [batch[0], I[ idx[ idx0:idx1 ] ]], batch[1]\n",
    "\n",
    "            idx0 = idx1\n",
    "            if idx1 >= X.shape[0]:\n",
    "                break\n",
    "                \n",
    "def testGenerator( X, I, Y):\n",
    "\n",
    "    while True:\n",
    "        # suffled indices    \n",
    "        idx = np.random.permutation( X.shape[0])\n",
    "        # create image generator\n",
    "        datagen = ImageDataGenerator(\n",
    "                rescale=1./1)\n",
    "\n",
    "        batches = datagen.flow( X[idx], Y[idx], batch_size=64, shuffle=False)\n",
    "        idx0 = 0\n",
    "        for batch in batches:\n",
    "            idx1 = idx0 + batch[0].shape[0]\n",
    "\n",
    "            yield [batch[0], I[ idx[ idx0:idx1 ] ]], batch[1]\n",
    "\n",
    "            idx0 = idx1\n",
    "            if idx1 >= X.shape[0]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = optimizers.RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "\n",
    "# use unedited training images\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
    "\n",
    "# use augmented training images\n",
    "# history = model.fit_generator(testGenerator(tr_pairs[:, 0],tr_pairs[:, 1],tr_y), \n",
    "#                               steps_per_epoch=2, \n",
    "#                               epochs=10,\n",
    "#                               validation_data=testGenerator(te_pairs[:, 0],te_pairs[:, 1],te_y), \n",
    "#                               validation_steps=1, \n",
    "#                               verbose=1)\n",
    "\n",
    "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(tr_y, y_pred)\n",
    "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(te_y, y_pred)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1100px",
    "right": "20px",
    "top": "93px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
