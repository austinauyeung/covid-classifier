{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.applications import resnet50, vgg16\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer, Lambda, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from itertools import combinations\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to image directory\n",
    "cov = glob.glob('/Users/austinau-yeung/Documents/Georgia Tech/1/ECE6254/project/covid-chestxray-dataset-master/output/*')\n",
    "pne = glob.glob('/Users/austinau-yeung/Documents/Georgia Tech/1/ECE6254/project/pneumonia2/*')\n",
    "cov_avg = glob.glob('/Users/austinau-yeung/Documents/Georgia Tech/1/ECE6254/project/covidavg/*')\n",
    "\n",
    "# parameters\n",
    "# cov_train_num = 400\n",
    "# pne_train_num = 400\n",
    "cov_train_num = 100\n",
    "pne_train_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# select random subset of images for training\n",
    "cov_train = np.random.choice(cov,size=cov_train_num,replace=False)\n",
    "pne_train = np.random.choice(pne,size=pne_train_num,replace=False)\n",
    "cov = list(set(cov)-set(cov_train))\n",
    "pne = list(set(pne)-set(pne_train))\n",
    "cov_test = cov\n",
    "pne_test = pne\n",
    "\n",
    "cov_test_num = len(cov_test)\n",
    "pne_test_num = len(pne_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "IMG_DIM = (IMG_WIDTH,IMG_HEIGHT)\n",
    "\n",
    "# load training images\n",
    "cov_train_imgs = [img_to_array(load_img(img,target_size=IMG_DIM,color_mode=\"rgb\")) for img in cov_train]\n",
    "pne_train_imgs = [img_to_array(load_img(img,target_size=IMG_DIM,color_mode=\"rgb\")) for img in pne_train]\n",
    "\n",
    "# create corresponding labels\n",
    "train_imgs = np.array(cov_train_imgs+pne_train_imgs)\n",
    "train_imgs_scaled = train_imgs.astype('float32')/255\n",
    "train_labels = cov_train_num*['c']+pne_train_num*['p']\n",
    "\n",
    "# load test images and create corresponding labels\n",
    "cov_test_imgs = [img_to_array(load_img(img,target_size=IMG_DIM,color_mode=\"rgb\")) for img in cov_test]\n",
    "pne_test_imgs = [img_to_array(load_img(img,target_size=IMG_DIM,color_mode=\"rgb\")) for img in pne_test]\n",
    "test_imgs = np.array(cov_test_imgs+pne_test_imgs)\n",
    "test_imgs_scaled = test_imgs.astype('float32')/255\n",
    "test_labels = cov_test_num*['c']+pne_test_num*['p']\n",
    "\n",
    "# load average covid image\n",
    "covavg_imgs = np.array([img_to_array(load_img(img,target_size=IMG_DIM,color_mode=\"rgb\")) for img in cov_avg])\n",
    "covavg_imgs_scaled = covavg_imgs.astype('float32')/255\n",
    "\n",
    "input_shape = (IMG_HEIGHT,IMG_WIDTH,train_imgs.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class labels as 0/1\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_enc = le.transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese network referenced from the following:\n",
    "# https://github.com/keras-team/keras/blob/master/examples/mnist_siamese.py\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 2\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 1\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 1, y_true.dtype)))\n",
    "\n",
    "def create_pairs(x, class_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(class_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = class_indices[d][i], class_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            z1, z2 = class_indices[d][i], class_indices[dn][random.randrange(0,n+1)]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def create_all_pairs(x, class_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(class_indices[d]) for d in range(num_classes)])\n",
    "\n",
    "    # create all positive pairs for each class (two classes: (N choose 2)*2=N^2-N)\n",
    "    for d in range(num_classes):\n",
    "        comb = combinations(range(0,n),2) # select indices in class\n",
    "        for i in list(comb):\n",
    "            z1, z2 = class_indices[d][i[0]], class_indices[d][i[1]]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1]\n",
    "    \n",
    "    # create all possible negative pairs (two classes: N^2)\n",
    "    comb = combinations(range(0,num_classes),2) # select two different classes\n",
    "    for d in list(comb):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                z1, z2 = class_indices[d[0]][i], class_indices[d[1]][j]\n",
    "                pairs += [[x[z1], x[z2]]]\n",
    "                labels += [0]\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def covavg_pairs(x1,x2,class_indices):\n",
    "    #x1: avgcov, x2: covtest, x3: pnetest\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(class_indices[d]) for d in range(num_classes)])\n",
    "    \n",
    "    # create all positive pairs for each class\n",
    "    for i in range(n):\n",
    "        z = class_indices[0][i]\n",
    "        pairs += [[x1[0], x2[z]]]\n",
    "        labels += [1]\n",
    "    \n",
    "    # create all possible negative pairs\n",
    "    for i in range(n):\n",
    "        z = class_indices[1][i]\n",
    "        pairs += [[x1[0], x2[z]]]\n",
    "        labels += [0] \n",
    "                \n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def vggnet_base(input_shape):\n",
    "\n",
    "    # train last 2 layers (top 3 layers not included)\n",
    "    vggnet = vgg16.VGG16(include_top=False,weights='imagenet',input_shape=input_shape,pooling='avg')\n",
    "    for layer in vggnet.layers[-5:]:\n",
    "        layer.trainable=True\n",
    "    for layer in vggnet.layers[:-5]:\n",
    "        layer.trainable=False\n",
    "    x = vggnet.output\n",
    "    \n",
    "#     imgIn = Input(shape=input_shape)\n",
    "#     x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "#     x = Dropout(0.1)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Dense(512, activation='relu')(x)\n",
    "#     x = Dropout(0.1)(x)\n",
    "#     x = Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "    return Model(vggnet.input,x)\n",
    "#     return Model(imgIn,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set original size: 19900\n",
      "Testing set original size: 12403\n",
      "Classification set original size: 158\n",
      "Training set new size: 2048\n",
      "Testing set new size: 1024\n",
      "Classification set new size: 158\n"
     ]
    }
   ],
   "source": [
    "# create positive and negative pairs\n",
    "idx = [np.where(train_labels_enc==i)[0] for i in range(num_classes)]\n",
    "tr_pairs, tr_y = create_all_pairs(train_imgs_scaled,idx)\n",
    "\n",
    "idx = [np.where(test_labels_enc==i)[0] for i in range(num_classes)]\n",
    "te_pairs, te_y = create_all_pairs(test_imgs_scaled,idx)\n",
    "cl_pairs, cl_y = covavg_pairs(covavg_imgs_scaled,test_imgs_scaled,idx)\n",
    "\n",
    "print('Training set original size: '+str(tr_pairs.shape[0]))\n",
    "print('Testing set original size: '+str(te_pairs.shape[0]))\n",
    "print('Classification set original size: '+str(cl_pairs.shape[0]))\n",
    "\n",
    "# use random subset of all pairs (might need to adjust to ensure class balance)\n",
    "num_tr_pairs = 2048;\n",
    "idx = random.sample(range(tr_pairs.shape[0]),num_tr_pairs)\n",
    "tr_pairs = np.array([tr_pairs[x] for x in idx])\n",
    "tr_y = np.array([tr_y[x] for x in idx])\n",
    "\n",
    "num_te_pairs = 1024;\n",
    "idx = random.sample(range(te_pairs.shape[0]),num_te_pairs)\n",
    "te_pairs = np.array([te_pairs[x] for x in idx])\n",
    "te_y = np.array([te_y[x] for x in idx])\n",
    "\n",
    "num_cl_pairs = cl_pairs.shape[0];\n",
    "idx = random.sample(range(cl_pairs.shape[0]),num_cl_pairs)\n",
    "cl_pairs = np.array([cl_pairs[x] for x in idx])\n",
    "cl_y = np.array([cl_y[x] for x in idx])\n",
    "\n",
    "print('Training set new size: '+str(tr_pairs.shape[0]))\n",
    "print('Testing set new size: '+str(te_pairs.shape[0]))\n",
    "print('Classification set new size: '+str(cl_pairs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 128)          14796864    input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,796,864\n",
      "Trainable params: 7,161,600\n",
      "Non-trainable params: 7,635,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create siamese network with euclidean distance as final layer\n",
    "base_network = vggnet_base(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance,output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2048/2048 [==============================] - 706s 345ms/step - loss: 1.0368 - accuracy: 0.5234\n",
      "Epoch 2/10\n",
      "2048/2048 [==============================] - 694s 339ms/step - loss: 0.6816 - accuracy: 0.7505\n",
      "Epoch 3/10\n",
      "2048/2048 [==============================] - 693s 338ms/step - loss: 0.2789 - accuracy: 0.9668\n",
      "Epoch 4/10\n",
      "2048/2048 [==============================] - 691s 337ms/step - loss: 0.1545 - accuracy: 0.9971\n",
      "Epoch 5/10\n",
      "2048/2048 [==============================] - 692s 338ms/step - loss: 0.1162 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2048/2048 [==============================] - 692s 338ms/step - loss: 0.0980 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2048/2048 [==============================] - 772s 377ms/step - loss: 0.0845 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2048/2048 [==============================] - 830s 405ms/step - loss: 0.0796 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2048/2048 [==============================] - 705s 344ms/step - loss: 0.0739 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2048/2048 [==============================] - 690s 337ms/step - loss: 0.0692 - accuracy: 1.0000\n",
      "* Accuracy on training set: 100.00%\n",
      "* Accuracy on test set: 96.48%\n",
      "* Accuracy on classification set: 97.47%\n"
     ]
    }
   ],
   "source": [
    "adm = optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss=contrastive_loss, optimizer=adm, metrics=[accuracy])\n",
    "\n",
    "# use unedited training images\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "#           validation_data=([te_pairs[:10, 0], te_pairs[:10, 1]], te_y[:10]), # validate on small subset of testing dataset\n",
    "          shuffle=False)\n",
    "\n",
    "tr_y_dist = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(tr_y, tr_y_dist)\n",
    "te_y_dist = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(te_y, te_y_dist)\n",
    "cl_y_dist = model.predict([cl_pairs[:, 0], cl_pairs[:, 1]])\n",
    "cl_acc = compute_accuracy(cl_y, cl_y_dist)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))\n",
    "print('* Accuracy on classification set: %0.2f%%' % (100 * cl_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "0.50048828125\n",
      "0.4931640625\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(np.mean(tr_y)) # show positive/negative balance\n",
    "print(np.mean(te_y)) # show positive/negative balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.0\n",
      "75.0\n",
      "4.0\n",
      "0.0\n",
      "1.0\n",
      "0.9493670886075949\n"
     ]
    }
   ],
   "source": [
    "def generate_label(y_pred, threshold):\n",
    "    '''Compute classification labels with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < threshold\n",
    "    return pred\n",
    "\n",
    "def generate_metrics(y_true,y_pred):\n",
    "    tp = sum(y_true+y_pred==2)\n",
    "    tn = sum(y_true+y_pred==0)\n",
    "    fp = sum(y_true-y_pred==-1)\n",
    "    fn = sum(y_true-y_pred==1)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    \n",
    "    return np.array([tp,tn,fp,fn,sensitivity,specificity])\n",
    "\n",
    "cl_y_pred = generate_label(cl_y_dist,1) # using half of margin for threshold\n",
    "tp,tn,fp,fn,sensitivity,specificity = generate_metrics(cl_y,cl_y_pred)\n",
    "print(tp)\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(sensitivity)\n",
    "print(specificity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1100px",
    "right": "20px",
    "top": "93px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
