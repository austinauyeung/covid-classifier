{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.applications import resnet50, vgg16\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer, Lambda, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from itertools import combinations\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to image directory\n",
    "cov = glob.glob('/Users/austinau-yeung/Documents/Georgia Tech/1/ECE6254/project/covid-chestxray-dataset-master/output/*')\n",
    "pne = glob.glob('/Users/austinau-yeung/Documents/Georgia Tech/1/ECE6254/project/pneumonia2/*')\n",
    "\n",
    "# parameters\n",
    "# cov_train_num = 400\n",
    "# pne_train_num = 400\n",
    "cov_train_num = 140\n",
    "pne_train_num = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# select random subset of images for training\n",
    "cov_train = np.random.choice(cov,size=cov_train_num,replace=False)\n",
    "pne_train = np.random.choice(pne,size=pne_train_num,replace=False)\n",
    "cov = list(set(cov)-set(cov_train))\n",
    "pne = list(set(pne)-set(pne_train))\n",
    "cov_test = cov\n",
    "pne_test = pne\n",
    "\n",
    "cov_test_num = len(cov_test)\n",
    "pne_test_num = len(pne_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "IMG_DIM = (IMG_WIDTH,IMG_HEIGHT)\n",
    "\n",
    "# load training images\n",
    "cov_train_imgs = [img_to_array(load_img(img,target_size=IMG_DIM,color_mode=\"rgb\")) for img in cov_train]\n",
    "pne_train_imgs = [img_to_array(load_img(img,target_size=IMG_DIM,color_mode=\"rgb\")) for img in pne_train]\n",
    "\n",
    "# create corresponding labels\n",
    "train_imgs = np.array(cov_train_imgs+pne_train_imgs)\n",
    "train_imgs_scaled = train_imgs.astype('float32')/255\n",
    "train_labels = cov_train_num*['c']+pne_train_num*['p']\n",
    "\n",
    "# load test images and create corresponding labels\n",
    "cov_test_imgs = [img_to_array(load_img(img,target_size=IMG_DIM,color_mode=\"rgb\")) for img in cov_test]\n",
    "pne_test_imgs = [img_to_array(load_img(img,target_size=IMG_DIM,color_mode=\"rgb\")) for img in pne_test]\n",
    "test_imgs = np.array(cov_test_imgs+pne_test_imgs)\n",
    "test_imgs_scaled = test_imgs.astype('float32')/255\n",
    "test_labels = cov_test_num*['c']+pne_test_num*['p']\n",
    "\n",
    "input_shape = (IMG_HEIGHT,IMG_WIDTH,train_imgs.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class labels as 0/1\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_enc = le.transform(train_labels)\n",
    "test_labels_enc = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese network referenced from the following:\n",
    "# https://github.com/keras-team/keras/blob/master/examples/mnist_siamese.py\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 2\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 1\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 1, y_true.dtype)))\n",
    "#     return K.mean(y_pred[1])\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][random.randrange(0,n+1)]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def create_all_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(num_classes)])\n",
    "\n",
    "    # create all positive pairs for each class (two classes: (N choose 2)*2=N^2-N)\n",
    "    for d in range(num_classes):\n",
    "        comb = combinations(range(0,n),2) # select indices in class\n",
    "        for i in list(comb):\n",
    "            z1, z2 = digit_indices[d][i[0]], digit_indices[d][i[1]]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1]\n",
    "    \n",
    "    # create all possible negative pairs (two classes: N^2)\n",
    "    comb = combinations(range(0,num_classes),2) # select two different classes\n",
    "    for d in list(comb):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                z1, z2 = digit_indices[d[0]][i], digit_indices[d[1]][j]\n",
    "                pairs += [[x[z1], x[z2]]]\n",
    "                labels += [0]\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def vggnet_base(input_shape):\n",
    "\n",
    "    # train last 2 layers (top 3 layers not included)\n",
    "    vggnet = vgg16.VGG16(include_top=False,weights='imagenet',input_shape=input_shape,pooling='avg')\n",
    "    for layer in vggnet.layers[-5:]:\n",
    "        layer.trainable=True\n",
    "    for layer in vggnet.layers[:-5]:\n",
    "        layer.trainable=False\n",
    "    x = vggnet.output\n",
    "    \n",
    "#     imgIn = Input(shape=input_shape)\n",
    "#     x = Flatten()(imgIn)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "#     x = Dropout(0.1)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Dense(512, activation='relu')(x)\n",
    "#     x = Dropout(0.1)(x)\n",
    "#     x = Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "    return Model(vggnet.input,x)\n",
    "#     return Model(imgIn,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set original size: 39060\n",
      "Testing set original size: 3003\n",
      "Training set new size: 4096\n",
      "Testing set new size: 2048\n"
     ]
    }
   ],
   "source": [
    "# create positive and negative pairs\n",
    "idx = [np.where(train_labels_enc==i)[0] for i in range(num_classes)]\n",
    "tr_pairs, tr_y = create_all_pairs(train_imgs_scaled,idx)\n",
    "\n",
    "idx = [np.where(test_labels_enc==i)[0] for i in range(num_classes)]\n",
    "te_pairs, te_y = create_all_pairs(test_imgs_scaled,idx)\n",
    "\n",
    "print('Training set original size: '+str(tr_pairs.shape[0]))\n",
    "print('Testing set original size: '+str(te_pairs.shape[0]))\n",
    "\n",
    "# use random subset of all pairs (might need to adjust to ensure class balance)\n",
    "num_tr_pairs = 4096;\n",
    "idx = random.sample(range(tr_pairs.shape[0]),num_tr_pairs)\n",
    "tr_pairs = np.array([tr_pairs[x] for x in idx])\n",
    "tr_y = np.array([tr_y[x] for x in idx])\n",
    "\n",
    "num_te_pairs = 2048;\n",
    "idx = random.sample(range(te_pairs.shape[0]),num_te_pairs)\n",
    "te_pairs = np.array([te_pairs[x] for x in idx])\n",
    "te_y = np.array([te_y[x] for x in idx])\n",
    "\n",
    "print('Training set new size: '+str(tr_pairs.shape[0]))\n",
    "print('Testing set new size: '+str(te_pairs.shape[0]))\n",
    "\n",
    "# setup image augmentation on pairs of images using ImageDataGenerator, referenced from the following:\n",
    "# https://github.com/keras-team/keras/issues/3386#issuecomment-237555199\n",
    "\n",
    "def trainGenerator( X, I, Y):\n",
    "\n",
    "    while True:\n",
    "        # shuffled indices    \n",
    "        idx = np.random.permutation( X.shape[0])\n",
    "        # create image generator\n",
    "        datagen = ImageDataGenerator(\n",
    "                fill_mode='constant',\n",
    "                cval=0,\n",
    "                rescale=1./1,\n",
    "                featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,  # set each sample mean to 0\n",
    "                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                zca_whitening=False,  # apply ZCA whitening\n",
    "                rotation_range=5, #180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                width_shift_range=0.05, #0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.05, #0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                horizontal_flip=True,  # randomly flip images\n",
    "                vertical_flip=False)  # randomly flip images\n",
    "\n",
    "        batches = datagen.flow( X[idx], Y[idx], batch_size=64, shuffle=False)\n",
    "        idx0 = 0\n",
    "        for batch in batches:\n",
    "            idx1 = idx0 + batch[0].shape[0]\n",
    "\n",
    "            yield [batch[0], I[ idx[ idx0:idx1 ] ]], batch[1]\n",
    "\n",
    "            idx0 = idx1\n",
    "            if idx1 >= X.shape[0]:\n",
    "                break\n",
    "                \n",
    "def testGenerator( X, I, Y):\n",
    "\n",
    "    while True:\n",
    "        # suffled indices    \n",
    "        idx = np.random.permutation( X.shape[0])\n",
    "        # create image generator\n",
    "        datagen = ImageDataGenerator(\n",
    "                rescale=1./1)\n",
    "\n",
    "        batches = datagen.flow( X[idx], Y[idx], batch_size=64, shuffle=False)\n",
    "        idx0 = 0\n",
    "        for batch in batches:\n",
    "            idx1 = idx0 + batch[0].shape[0]\n",
    "\n",
    "            yield [batch[0], I[ idx[ idx0:idx1 ] ]], batch[1]\n",
    "\n",
    "            idx0 = idx1\n",
    "            if idx1 >= X.shape[0]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 128)          14796864    input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,796,864\n",
      "Trainable params: 7,161,600\n",
      "Non-trainable params: 7,635,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create siamese network with euclidean distance as final layer\n",
    "base_network = vggnet_base(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance,output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4096/4096 [==============================] - 1376s 336ms/step - loss: 0.8227 - accuracy: 0.6758\n",
      "Epoch 2/10\n",
      "4096/4096 [==============================] - 1376s 336ms/step - loss: 0.1832 - accuracy: 0.9817\n",
      "Epoch 3/10\n",
      "4096/4096 [==============================] - 1376s 336ms/step - loss: 0.0891 - accuracy: 0.9985\n",
      "Epoch 4/10\n",
      "4096/4096 [==============================] - 1375s 336ms/step - loss: 0.0749 - accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "4096/4096 [==============================] - 1378s 337ms/step - loss: 0.0653 - accuracy: 0.9998\n",
      "Epoch 6/10\n",
      "4096/4096 [==============================] - 1376s 336ms/step - loss: 0.0563 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4096/4096 [==============================] - 1373s 335ms/step - loss: 0.0503 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4096/4096 [==============================] - 1403s 342ms/step - loss: 0.0459 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4096/4096 [==============================] - 1467s 358ms/step - loss: 0.0416 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4096/4096 [==============================] - 1429s 349ms/step - loss: 0.0387 - accuracy: 1.0000\n",
      "* Accuracy on training set: 100.00%\n",
      "* Accuracy on test set: 95.36%\n"
     ]
    }
   ],
   "source": [
    "adm = optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss=contrastive_loss, optimizer=adm, metrics=[accuracy])\n",
    "\n",
    "# use unedited training images\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "#           validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y),\n",
    "          shuffle=False)\n",
    "\n",
    "# use augmented training images\n",
    "# history = model.fit_generator(testGenerator(tr_pairs[:, 0],tr_pairs[:, 1],tr_y), \n",
    "#                               steps_per_epoch=1, \n",
    "#                               epochs=100,\n",
    "#                               validation_data=testGenerator(te_pairs[:, 0],te_pairs[:, 1],te_y), \n",
    "#                               validation_steps=1, \n",
    "#                               verbose=1)\n",
    "\n",
    "tr_y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(tr_y, tr_y_pred)\n",
    "te_y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(te_y, te_y_pred)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "0.494873046875\n",
      "0.48974609375\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(np.mean(tr_y)) # show positive/negative balance\n",
    "print(np.mean(te_y)) # show positive/negative balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1100px",
    "right": "20px",
    "top": "93px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
